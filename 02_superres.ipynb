{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7771cc-880a-4722-86d1-6af4698ca144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms.v2.functional import to_dtype, to_pil_image\n",
    "from torcheval.metricss.functional import peak_signal_noise_ratio\n",
    "from srgan import Generator, Discriminator\n",
    "from main import EnhanceDataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "op = os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369f7174-f0c3-4f0e-b7bd-53435522acc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_srgan(generator, discriminator, train_loader, val_loader, n_epochs, device):\n",
    "    # Loss functions\n",
    "    criterion_gan = nn.BCELoss()\n",
    "    criterion_content = nn.MSELoss()\n",
    "\n",
    "    # Optimizers\n",
    "    opt_g = optim.Adam(generator.parameters(), lr=0.001)\n",
    "    opt_d = optim.Adam(discriminator.parameters(), lr=0.001)\n",
    "    steppers = [optim.lr_scheduler.StepLR(opt_g, 10, gamma=0.1),\n",
    "                optim.lr_scheduler.StepLR(opt_d, 10, gamma=0.1)]\n",
    "\n",
    "    best_psnr_epoch = best_psnr = 0\n",
    "    n_batches = len(train_loader) + len(val_loader)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_train_loss = epoch_val_loss = train_psnr = val_psnr = 0\n",
    "        with tqdm(total=n_batches) as pbar:\n",
    "            generator.train()\n",
    "            discriminator.train()\n",
    "            for lr_images, hr_images in train_loader:\n",
    "                batch_size = lr_images.size(0)\n",
    "\n",
    "                # Move to device\n",
    "                lr_images = lr_images.to(device)\n",
    "                hr_images = hr_images.to(device)\n",
    "\n",
    "                # Ground truths\n",
    "                real_labels = torch.ones(batch_size, 1).to(device)\n",
    "                fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "                opt_g.zero_grad()\n",
    "\n",
    "                # Generate SR images\n",
    "                sr_images = generator(lr_images)\n",
    "\n",
    "                # Adversarial loss\n",
    "                gen_validity = discriminator(sr_images)\n",
    "                loss_gan = criterion_gan(gen_validity, real_labels)\n",
    "\n",
    "                # Content loss\n",
    "                loss_content = criterion_content(sr_images, hr_images)\n",
    "\n",
    "                # Total generator loss\n",
    "                loss_g = loss_content + 1e-3 * loss_gan\n",
    "                loss_g.backward()\n",
    "                opt_g.step()\n",
    "\n",
    "                opt_d.zero_grad()\n",
    "\n",
    "                # Loss on real images\n",
    "                real_validity = discriminator(hr_images)\n",
    "                loss_real = criterion_gan(real_validity, real_labels)\n",
    "\n",
    "                # Loss on fake images\n",
    "                fake_validity = discriminator(sr_images.detach())\n",
    "                loss_fake = criterion_gan(fake_validity, fake_labels)\n",
    "\n",
    "                # Total discriminator loss\n",
    "                loss_d = (loss_real + loss_fake) / 2\n",
    "                loss_d.backward()\n",
    "                opt_d.step()\n",
    "                litem = (loss_d.item() + loss_g.item()) / 2\n",
    "                epoch_train_loss += litem\n",
    "\n",
    "                train_psnr += peak_signal_noise_ratio(\n",
    "                    sr_images, hr_images, data_range=1.0\n",
    "                )\n",
    "\n",
    "                pbar.set_postfix_str(f\"Train loss: {litem:.4f}\")\n",
    "                pbar.update(1)\n",
    "\n",
    "            generator.eval()\n",
    "            discriminator.eval()\n",
    "            for lr_images, hr_images in val_loader:\n",
    "                batch_size = lr_images.size(0)\n",
    "\n",
    "                # Move to device\n",
    "                lr_images = lr_images.to(device)\n",
    "                hr_images = hr_images.to(device)\n",
    "\n",
    "                # Generate SR images\n",
    "                with torch.no_grad():\n",
    "                    sr_images = generator(lr_images)\n",
    "\n",
    "                    gen_validity = discriminator(sr_images)\n",
    "                real_labels = torch.ones(batch_size, 1).to(device)\n",
    "                loss_gan = criterion_gan(gen_validity, real_labels)\n",
    "\n",
    "                # Content loss\n",
    "                loss_content = criterion_content(sr_images, hr_images)\n",
    "\n",
    "                # Total generator loss\n",
    "                loss_g = loss_content + 1e-3 * loss_gan\n",
    "                litem = loss_g.item()\n",
    "                epoch_val_loss += litem\n",
    "                val_psnr += peak_signal_noise_ratio(\n",
    "                    sr_images, hr_images, data_range=1.0\n",
    "                )\n",
    "                pbar.set_postfix_str(f\"Val loss: {litem:.4f}\")\n",
    "                pbar.update(1)\n",
    "            [stepper.step() for stepper in steppers]\n",
    "        epoch_train_loss /= len(train_loader)\n",
    "        epoch_val_loss /= len(val_loader)\n",
    "        train_psnr /= len(train_loader)\n",
    "        val_psnr /= len(val_loader)\n",
    "        current_psnr = (val_psnr * len(val_loader) + train_psnr * len(train_loader)) / n_batches\n",
    "        if current_psnr > best_psnr:\n",
    "            best_psnr = current_psnr\n",
    "            best_psnr_epoch = epoch\n",
    "            print(f'Better model found at epoch {epoch}')  # NOQA: T201\n",
    "            torch.save(generator.state_dict(), \"models/generator-best.pth\")\n",
    "            torch.save(discriminator.state_dict(), \"models/discriminator-best.pth\")\n",
    "        elif epoch - best_psnr_epoch > 5:\n",
    "            print(f'Stopping at epoch {epoch} - best epoch was {best_psnr_epoch}')  # NOQA: T201\n",
    "            break\n",
    "\n",
    "        print(  # NOQA: T201\n",
    "            f\"Train: {epoch_train_loss:.4f}; Val: {epoch_val_loss:.4f};\",\n",
    "            f\"Train PSNR: {train_psnr:.4f}; Val PSNR: {val_psnr:.4f}\",\n",
    "        )\n",
    "\n",
    "\n",
    "def collate_sr(batch):\n",
    "    images, labels = map(torch.stack, zip(*batch))\n",
    "    images = to_dtype(images, torch.float32, scale=True)\n",
    "    labels = to_dtype(labels, torch.float32, scale=True)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb63d307-e382-4041-83fe-9bd5f5a92d6a",
   "metadata": {},
   "source": [
    "# Train the SRGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02485b6a-c7fb-4910-b599-0fae5ae2d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(n_epochs=40):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    generator = Generator().to(device)\n",
    "    if op.exists('models/generator-best.pth'):\n",
    "        generator.load_state_dict(torch.load(\"models/generator-best.pth\", weights_only=True))\n",
    "    discriminator = Discriminator().to(device)\n",
    "    if op.exists('models/discriminator-best.pth'):\n",
    "        discriminator.load_state_dict(torch.load(\"models/discriminator-best.pth\", weights_only=True))\n",
    "\n",
    "    train_ds = EnhanceDataset(\"denoised/train/train/\", \"archive/train/gt/\")\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=4, shuffle=True, pin_memory=True, collate_fn=collate_sr\n",
    "    )\n",
    "    val_ds = EnhanceDataset(\"denoised/val/val/\", \"archive/val/gt/\")\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=4, shuffle=True, pin_memory=True, collate_fn=collate_sr\n",
    "    )\n",
    "\n",
    "    train_srgan(generator, discriminator, train_loader, val_loader, n_epochs, device)\n",
    "\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3b26bf-0e54-4cb0-8d49-fa9195f183a0",
   "metadata": {},
   "source": [
    "## Create 4x Scaled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8848655-c0de-43e5-afe5-13996e25ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"denoised/test/\"\n",
    "os.makedirs('hr-output', exist_ok=True)\n",
    "for file in tqdm(os.listdir(root)):\n",
    "    img = read_image(op.join(root, file))\n",
    "    img = to_dtype(img, torch.float32, scale=True)\n",
    "    with torch.no_grad():\n",
    "        out = model(img.unsqueeze(0))\n",
    "    out = out.squeeze(0)\n",
    "    to_pil_image(out).save(op.join(\"hr-output\", file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
